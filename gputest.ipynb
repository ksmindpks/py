{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35ff07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU name: NVIDIA GeForce GTX 1060 3GB\n",
      "GPU tensor: tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# 테스트\n",
    "x = torch.tensor([1.0, 2.0, 3.0]).cuda()\n",
    "print(f\"GPU tensor: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5e7ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU tensor: tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\602-01\\AppData\\Local\\Temp\\ipykernel_8580\\770461706.py:8: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:80.)\n",
      "  gpu_tensor = torch.cuda.FloatTensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# 이제 작동해야 함\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = torch.cuda.FloatTensor([1, 2, 3])\n",
    "    print(f\"GPU tensor: {gpu_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000e35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='cuda:0')\n",
      "tensor([[0.0558]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cpu = torch.FloatTensor([1, 2, 3])\n",
    "gpu = torch.cuda.FloatTensor([1, 2, 3])\n",
    "tensor = torch.rand((1, 1), device=device)\n",
    "print(device)\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9260e3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ab979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory: 0.0MB / 0.0MB\n"
     ]
    }
   ],
   "source": [
    "# GPU 메모리 사용량 모니터링\n",
    "print(f\"GPU Memory: {torch.cuda.memory_allocated()/1024**2:.1f}MB / {torch.cuda.max_memory_allocated()/1024**2:.1f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789fa8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTX 1060 3GB 한계 성능 테스트\n",
      "============================================================\n",
      "총 GPU 메모리: 3.00 GB\n",
      "\n",
      "1. 최대 단일 텐서 크기 한계\n",
      "크기 1000x1000: 11.9MB 성공\n",
      "크기 1200x1200: 13.6MB 성공\n",
      "크기 1400x1400: 15.6MB 성공\n",
      "크기 1600x1600: 17.9MB 성공\n",
      "크기 1800x1800: 20.5MB 성공\n",
      "크기 2000x2000: 24.1MB 성공\n",
      "크기 2200x2200: 26.6MB 성공\n",
      "크기 2400x2400: 30.1MB 성공\n",
      "크기 2600x2600: 34.1MB 성공\n",
      "크기 2800x2800: 38.1MB 성공\n",
      "크기 3000x3000: 42.5MB 성공\n",
      "크기 3200x3200: 48.1MB 성공\n",
      "크기 3400x3400: 52.2MB 성공\n",
      "크기 3600x3600: 58.1MB 성공\n",
      "크기 3800x3800: 64.1MB 성공\n",
      "크기 4000x4000: 70.1MB 성공\n",
      "크기 4200x4200: 76.1MB 성공\n",
      "크기 4400x4400: 82.1MB 성공\n",
      "크기 4600x4600: 88.8MB 성공\n",
      "크기 4800x4800: 96.1MB 성공\n",
      "크기 5000x5000: 104.1MB 성공\n",
      "크기 5200x5200: 112.1MB 성공\n",
      "크기 5400x5400: 120.1MB 성공\n",
      "크기 5600x5600: 128.1MB 성공\n",
      "크기 5800x5800: 136.5MB 성공\n",
      "크기 6000x6000: 146.1MB 성공\n",
      "크기 6200x6200: 154.8MB 성공\n",
      "크기 6400x6400: 164.4MB 성공\n",
      "크기 6600x6600: 174.3MB 성공\n",
      "크기 6800x6800: 184.5MB 성공\n",
      "크기 7000x7000: 195.0MB 성공\n",
      "크기 7200x7200: 206.1MB 성공\n",
      "크기 7400x7400: 217.0MB 성공\n",
      "크기 7600x7600: 228.5MB 성공\n",
      "크기 7800x7800: 240.2MB 성공\n",
      "크기 8000x8000: 252.3MB 성공\n",
      "크기 8200x8200: 264.6MB 성공\n",
      "크기 8400x8400: 278.1MB 성공\n",
      "크기 8600x8600: 290.3MB 성공\n",
      "크기 8800x8800: 304.1MB 성공\n",
      "크기 9000x9000: 317.1MB 성공\n",
      "크기 9200x9200: 331.0MB 성공\n",
      "크기 9400x9400: 346.1MB 성공\n",
      "크기 9600x9600: 360.1MB 성공\n",
      "크기 9800x9800: 374.5MB 성공\n",
      "크기 10000x10000: 390.1MB 성공\n",
      "크기 10200x10200: 405.0MB 성공\n",
      "크기 10400x10400: 420.7MB 성공\n",
      "크기 10600x10600: 436.7MB 성공\n",
      "크기 10800x10800: 453.1MB 성공\n",
      "크기 11000x11000: 470.1MB 성공\n",
      "크기 11200x11200: 486.6MB 성공\n",
      "크기 11400x11400: 504.1MB 성공\n",
      "크기 11600x11600: 522.1MB 성공\n",
      "크기 11800x11800: 540.1MB 성공\n",
      "크기 12000x12000: 558.1MB 성공\n",
      "크기 12200x12200: 576.1MB 성공\n",
      "크기 12400x12400: 594.7MB 성공\n",
      "크기 12600x12600: 614.1MB 성공\n",
      "크기 12800x12800: 634.1MB 성공\n",
      "크기 13000x13000: 652.8MB 성공\n",
      "크기 13200x13200: 672.8MB 성공\n",
      "크기 13400x13400: 693.1MB 성공\n",
      "크기 13600x13600: 714.1MB 성공\n",
      "크기 13800x13800: 734.6MB 성공\n",
      "크기 14000x14000: 756.1MB 성공\n",
      "크기 14200x14200: 778.1MB 성공\n",
      "크기 14400x14400: 800.1MB 성공\n",
      "크기 14600x14600: 822.1MB 성공\n",
      "크기 14800x14800: 844.1MB 성공\n",
      "크기 15000x15000: 866.4MB 성공\n",
      "크기 15200x15200: 890.1MB 성공\n",
      "크기 15400x15400: 912.8MB 성공\n",
      "크기 15600x15600: 936.5MB 성공\n",
      "크기 15800x15800: 960.4MB 성공\n",
      "크기 16000x16000: 984.7MB 성공\n",
      "크기 16200x16200: 1010.1MB 성공\n",
      "크기 16400x16400: 1034.1MB 성공\n",
      "크기 16600x16600: 1060.1MB 성공\n",
      "크기 16800x16800: 1084.8MB 성공\n",
      "크기 17000x17000: 1110.6MB 성공\n",
      "크기 17200x17200: 1136.7MB 성공\n",
      "크기 17400x17400: 1163.1MB 성공\n",
      "크기 17600x17600: 1190.1MB 성공\n",
      "크기 17800x17800: 1216.8MB 성공\n",
      "크기 18000x18000: 1244.1MB 성공\n",
      "크기 18200x18200: 1272.1MB 성공\n",
      "크기 18400x18400: 1300.1MB 성공\n",
      "크기 18600x18600: 1328.1MB 성공\n",
      "크기 18800x18800: 1356.4MB 성공\n",
      "크기 19000x19000: 1386.1MB 성공\n",
      "크기 19200x19200: 1414.4MB 성공\n",
      "크기 19400x19400: 1444.1MB 성공\n",
      "크기 19600x19600: 1474.1MB 성공\n",
      "크기 19800x19800: 1504.1MB 성공\n",
      "최대 단일 텐서: 19800x19800\n",
      "\n",
      "2. 최대 배치 크기 테스트 (224x224 이미지)\n",
      "배치 크기 1: 14.0MB\n",
      "배치 크기 2: 14.5MB\n",
      "배치 크기 3: 15.1MB\n",
      "배치 크기 4: 15.7MB\n",
      "배치 크기 5: 16.3MB\n",
      "배치 크기 6: 16.8MB\n",
      "배치 크기 7: 17.4MB\n",
      "배치 크기 8: 18.0MB\n",
      "배치 크기 9: 18.6MB\n",
      "배치 크기 10: 19.2MB\n",
      "배치 크기 11: 19.7MB\n",
      "배치 크기 12: 20.3MB\n",
      "배치 크기 13: 20.9MB\n",
      "배치 크기 14: 21.9MB\n",
      "배치 크기 15: 22.1MB\n",
      "배치 크기 16: 22.6MB\n",
      "배치 크기 17: 23.2MB\n",
      "배치 크기 18: 23.8MB\n",
      "배치 크기 19: 24.4MB\n",
      "배치 크기 20: 25.5MB\n",
      "배치 크기 21: 25.5MB\n",
      "배치 크기 22: 26.1MB\n",
      "배치 크기 23: 27.5MB\n",
      "배치 크기 24: 27.5MB\n",
      "배치 크기 25: 27.8MB\n",
      "배치 크기 26: 28.4MB\n",
      "배치 크기 27: 29.5MB\n",
      "배치 크기 28: 29.6MB\n",
      "배치 크기 29: 30.1MB\n",
      "배치 크기 30: 31.5MB\n",
      "배치 크기 31: 31.5MB\n",
      "배치 크기 32: 31.9MB\n",
      "배치 크기 33: 32.5MB\n",
      "배치 크기 34: 33.5MB\n",
      "배치 크기 35: 33.6MB\n",
      "배치 크기 36: 34.2MB\n",
      "배치 크기 37: 35.5MB\n",
      "배치 크기 38: 35.5MB\n",
      "배치 크기 39: 35.9MB\n",
      "배치 크기 40: 36.5MB\n",
      "배치 크기 41: 37.5MB\n",
      "배치 크기 42: 37.7MB\n",
      "배치 크기 43: 38.2MB\n",
      "배치 크기 44: 39.5MB\n",
      "배치 크기 45: 39.6MB\n",
      "배치 크기 46: 40.0MB\n",
      "배치 크기 47: 40.5MB\n",
      "배치 크기 48: 41.6MB\n",
      "배치 크기 49: 41.7MB\n",
      "배치 크기 50: 42.3MB\n",
      "배치 크기 51: 43.6MB\n",
      "배치 크기 52: 43.6MB\n",
      "배치 크기 53: 44.0MB\n",
      "배치 크기 54: 45.6MB\n",
      "배치 크기 55: 45.6MB\n",
      "배치 크기 56: 45.8MB\n",
      "배치 크기 57: 46.3MB\n",
      "배치 크기 58: 47.6MB\n",
      "배치 크기 59: 47.6MB\n",
      "배치 크기 60: 48.1MB\n",
      "배치 크기 61: 49.6MB\n",
      "배치 크기 62: 49.6MB\n",
      "배치 크기 63: 49.8MB\n",
      "배치 크기 64: 50.4MB\n",
      "최대 배치 크기 (224x224): 64\n",
      "\n",
      "3. 훈련 시 최대 배치 크기\n",
      "훈련 배치 1: 27.7MB\n",
      "훈련 배치 2: 29.1MB\n",
      "훈련 배치 3: 29.0MB\n",
      "훈련 배치 4: 29.8MB\n",
      "훈련 배치 5: 30.1MB\n",
      "훈련 배치 6: 30.7MB\n",
      "훈련 배치 7: 31.2MB\n",
      "훈련 배치 8: 32.2MB\n",
      "훈련 배치 9: 32.7MB\n",
      "훈련 배치 10: 33.3MB\n",
      "훈련 배치 11: 33.3MB\n",
      "훈련 배치 12: 34.6MB\n",
      "훈련 배치 13: 34.7MB\n",
      "훈련 배치 14: 35.3MB\n",
      "훈련 배치 15: 35.7MB\n",
      "훈련 배치 16: 36.2MB\n",
      "훈련 배치 17: 36.6MB\n",
      "훈련 배치 18: 37.6MB\n",
      "훈련 배치 19: 37.8MB\n",
      "훈련 배치 20: 39.1MB\n",
      "훈련 배치 21: 39.4MB\n",
      "훈련 배치 22: 39.7MB\n",
      "훈련 배치 23: 40.1MB\n",
      "훈련 배치 24: 41.1MB\n",
      "훈련 배치 25: 41.5MB\n",
      "훈련 배치 26: 41.8MB\n",
      "훈련 배치 27: 42.9MB\n",
      "훈련 배치 28: 43.2MB\n",
      "훈련 배치 29: 43.6MB\n",
      "훈련 배치 30: 44.6MB\n",
      "훈련 배치 31: 45.4MB\n",
      "훈련 배치 32: 46.1MB\n",
      "훈련 배치 33: 46.2MB\n",
      "훈련 배치 34: 47.6MB\n",
      "훈련 배치 35: 47.8MB\n",
      "훈련 배치 36: 47.8MB\n",
      "훈련 배치 37: 49.1MB\n",
      "훈련 배치 38: 49.7MB\n",
      "훈련 배치 39: 50.1MB\n",
      "훈련 배치 40: 50.2MB\n",
      "훈련 배치 41: 51.3MB\n",
      "훈련 배치 42: 51.3MB\n",
      "훈련 배치 43: 52.4MB\n",
      "훈련 배치 44: 52.3MB\n",
      "훈련 배치 45: 53.6MB\n",
      "훈련 배치 46: 53.3MB\n",
      "훈련 배치 47: 54.8MB\n",
      "훈련 배치 48: 55.8MB\n",
      "훈련 배치 49: 55.4MB\n",
      "훈련 배치 50: 56.0MB\n",
      "훈련 배치 51: 56.9MB\n",
      "훈련 배치 52: 57.7MB\n",
      "훈련 배치 53: 57.8MB\n",
      "훈련 배치 54: 59.1MB\n",
      "훈련 배치 55: 59.0MB\n",
      "훈련 배치 56: 60.0MB\n",
      "훈련 배치 57: 59.8MB\n",
      "훈련 배치 58: 61.0MB\n",
      "훈련 배치 59: 61.0MB\n",
      "훈련 배치 60: 62.3MB\n",
      "훈련 배치 61: 63.0MB\n",
      "훈련 배치 62: 63.4MB\n",
      "훈련 배치 63: 63.6MB\n",
      "훈련 배치 64: 64.6MB\n",
      "최대 훈련 배치 크기: 64\n",
      "\n",
      "4. 해상도별 최대 배치 크기\n",
      "해상도 64x64: 최대 배치 99\n",
      "해상도 128x128: 최대 배치 99\n",
      "해상도 224x224: 최대 배치 46\n",
      "해상도 320x320: 최대 배치 24\n",
      "해상도 512x512: 최대 배치 9\n",
      "\n",
      "5. 행렬 곱셈 절대 한계\n",
      "크기 3000: 0.026초, 2103 GFLOPS, 160.9MB\n",
      "크기 3100: 0.030초, 1980 GFLOPS, 167.9MB\n",
      "크기 3200: 0.030초, 2150 GFLOPS, 176.0MB\n",
      "크기 3300: 0.036초, 2000 GFLOPS, 183.0MB\n",
      "크기 3400: 0.039초, 2029 GFLOPS, 190.2MB\n",
      "크기 3500: 0.044초, 1964 GFLOPS, 198.1MB\n",
      "크기 3600: 0.046초, 2013 GFLOPS, 207.3MB\n",
      "크기 3700: 0.057초, 1762 GFLOPS, 214.6MB\n",
      "크기 3800: 0.053초, 2063 GFLOPS, 225.0MB\n",
      "크기 3900: 0.065초, 1835 GFLOPS, 232.0MB\n",
      "크기 4000: 0.060초, 2144 GFLOPS, 242.9MB\n",
      "크기 4100: 0.186초, 741 GFLOPS, 250.3MB\n",
      "크기 4200: 0.508초, 292 GFLOPS, 261.2MB\n",
      "크기 4300: 0.295초, 539 GFLOPS, 269.5MB\n",
      "크기 4400: 0.377초, 451 GFLOPS, 279.7MB\n",
      "크기 4500: 0.461초, 395 GFLOPS, 291.1MB\n",
      "크기 4600: 0.439초, 443 GFLOPS, 300.0MB\n",
      "크기 4700: 0.464초, 448 GFLOPS, 310.7MB\n",
      "크기 4800: 0.405초, 547 GFLOPS, 321.8MB\n",
      "크기 4900: 0.507초, 464 GFLOPS, 333.5MB\n",
      "크기 5000: 0.507초, 493 GFLOPS, 345.3MB\n",
      "크기 5100: 0.509초, 521 GFLOPS, 357.9MB\n",
      "크기 5200: 0.584초, 482 GFLOPS, 369.9MB\n",
      "크기 5300: 0.605초, 492 GFLOPS, 381.9MB\n",
      "크기 5400: 0.676초, 466 GFLOPS, 393.9MB\n",
      "크기 5500: 0.681초, 489 GFLOPS, 405.9MB\n",
      "크기 5600: 0.638초, 551 GFLOPS, 417.9MB\n",
      "크기 5700: 0.856초, 433 GFLOPS, 429.9MB\n",
      "크기 5800: 1.021초, 382 GFLOPS, 442.9MB\n",
      "크기 5900: 1.141초, 360 GFLOPS, 456.3MB\n",
      "크기 6000: 0.996초, 434 GFLOPS, 471.9MB\n",
      "크기 6100: 0.802초, 566 GFLOPS, 483.9MB\n",
      "크기 6200: 1.011초, 471 GFLOPS, 497.8MB\n",
      "크기 6300: 0.987초, 507 GFLOPS, 513.9MB\n",
      "크기 6400: 0.932초, 563 GFLOPS, 526.6MB\n",
      "크기 6500: 1.117초, 492 GFLOPS, 543.9MB\n",
      "크기 6600: 1.042초, 552 GFLOPS, 556.4MB\n",
      "크기 6700: 1.199초, 502 GFLOPS, 573.9MB\n",
      "크기 6800: 1.153초, 545 GFLOPS, 587.1MB\n",
      "크기 6900: 1.226초, 536 GFLOPS, 603.9MB\n",
      "크기 7000: 1.279초, 536 GFLOPS, 618.6MB\n",
      "크기 7100: 1.363초, 525 GFLOPS, 634.8MB\n",
      "크기 7200: 1.452초, 514 GFLOPS, 651.9MB\n",
      "크기 7300: 1.525초, 510 GFLOPS, 669.9MB\n",
      "크기 7400: 1.469초, 552 GFLOPS, 684.6MB\n",
      "크기 7500: 1.727초, 489 GFLOPS, 701.6MB\n",
      "크기 7600: 1.743초, 504 GFLOPS, 718.9MB\n",
      "크기 7700: 1.950초, 468 GFLOPS, 736.4MB\n",
      "크기 7800: 1.956초, 485 GFLOPS, 754.1MB\n",
      "크기 7900: 2.068초, 477 GFLOPS, 772.1MB\n",
      "크기 8000: 2.107초, 486 GFLOPS, 790.3MB\n",
      "크기 8100: 2.144초, 496 GFLOPS, 808.7MB\n",
      "크기 8200: 2.211초, 499 GFLOPS, 827.4MB\n",
      "크기 8300: 2.216초, 516 GFLOPS, 846.3MB\n",
      "크기 8400: 2.132초, 556 GFLOPS, 867.9MB\n",
      "크기 8500: 2.056초, 597 GFLOPS, 885.9MB\n",
      "크기 8600: 2.009초, 633 GFLOPS, 904.3MB\n",
      "크기 8700: 2.217초, 594 GFLOPS, 924.1MB\n",
      "크기 8800: 1.827초, 746 GFLOPS, 945.9MB\n",
      "크기 8900: 2.459초, 573 GFLOPS, 964.4MB\n",
      "크기 9000: 2.264초, 644 GFLOPS, 984.9MB\n",
      "크기 9100: 2.375초, 635 GFLOPS, 1005.9MB\n",
      "크기 9200: 2.017초, 772 GFLOPS, 1026.5MB\n",
      "크기 9300: 2.686초, 599 GFLOPS, 1047.9MB\n",
      "크기 9400: 2.546초, 653 GFLOPS, 1071.9MB\n",
      "크기 9500: 2.898초, 592 GFLOPS, 1090.7MB\n",
      "크기 9600: 2.298초, 770 GFLOPS, 1113.9MB\n",
      "크기 9700: 3.073초, 594 GFLOPS, 1134.7MB\n",
      "크기 9800: 3.038초, 620 GFLOPS, 1157.0MB\n",
      "크기 9900: 3.288초, 590 GFLOPS, 1179.9MB\n",
      "최대 행렬 곱셈 크기: 9900x9900\n",
      "\n",
      "6. 메모리 대역폭 한계\n",
      "크기 2048: 대역폭 10.5 GB/s, 메모리 73.9MB\n",
      "크기 4096: 대역폭 10.1 GB/s, 메모리 121.9MB\n",
      "크기 6144: 대역폭 10.2 GB/s, 메모리 201.9MB\n",
      "크기 8192: 대역폭 10.1 GB/s, 메모리 313.9MB\n",
      "\n",
      "============================================================\n",
      "GTX 1060 3GB 절대 한계 요약\n",
      "============================================================\n",
      "최대 단일 텐서 크기: 19800x19800\n",
      "최대 추론 배치 (224x224): 64\n",
      "최대 훈련 배치 (224x224): 64\n",
      "최대 행렬 곱셈: 9900x9900\n",
      "\n",
      "권장 안전 사용량:\n",
      "- 추론 배치: 32 이하\n",
      "- 훈련 배치: 32 이하\n",
      "- 행렬 크기: 4950 이하\n",
      "- 메모리 사용률: 80% 이하 유지\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import gc\n",
    "\n",
    "def limit_performance_test():\n",
    "    print(\"GTX 1060 3GB 한계 성능 테스트\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"총 GPU 메모리: {total_memory:.2f} GB\")\n",
    "    \n",
    "    def cleanup():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    def get_memory_usage():\n",
    "        return torch.cuda.memory_allocated() / 1024**2\n",
    "    \n",
    "    # 1. 최대 단일 텐서 크기 한계 테스트\n",
    "    print(\"\\n1. 최대 단일 텐서 크기 한계\")\n",
    "    cleanup()\n",
    "    \n",
    "    max_size = 0\n",
    "    for size in range(1000, 20000, 200):\n",
    "        cleanup()\n",
    "        try:\n",
    "            tensor = torch.randn(size, size, device=device, dtype=torch.float32)\n",
    "            memory_used = get_memory_usage()\n",
    "            print(f\"크기 {size}x{size}: {memory_used:.1f}MB 성공\")\n",
    "            max_size = size\n",
    "            del tensor\n",
    "            \n",
    "            if memory_used > 2800:  # 거의 한계에 근접\n",
    "                break\n",
    "                \n",
    "        except RuntimeError as e:\n",
    "            print(f\"크기 {size}x{size}: 메모리 한계 도달\")\n",
    "            break\n",
    "    \n",
    "    print(f\"최대 단일 텐서: {max_size}x{max_size}\")\n",
    "    \n",
    "    # 2. 최대 배치 크기 테스트 (ResNet-like 모델)\n",
    "    print(\"\\n2. 최대 배치 크기 테스트 (224x224 이미지)\")\n",
    "    cleanup()\n",
    "    \n",
    "    # 실제 ResNet 구조와 유사한 모델\n",
    "    class TestCNN(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.features = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(3, 64, 7, stride=2, padding=3),\n",
    "                torch.nn.BatchNorm2d(64),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(3, stride=2, padding=1),\n",
    "                \n",
    "                torch.nn.Conv2d(64, 128, 3, padding=1),\n",
    "                torch.nn.BatchNorm2d(128),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(128, 128, 3, padding=1),\n",
    "                torch.nn.BatchNorm2d(128),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(2),\n",
    "                \n",
    "                torch.nn.Conv2d(128, 256, 3, padding=1),\n",
    "                torch.nn.BatchNorm2d(256),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(256, 256, 3, padding=1),\n",
    "                torch.nn.BatchNorm2d(256),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(2),\n",
    "                \n",
    "                torch.nn.AdaptiveAvgPool2d(1)\n",
    "            )\n",
    "            self.classifier = torch.nn.Linear(256, 1000)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.features(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "    \n",
    "    model = TestCNN().to(device)\n",
    "    max_batch = 0\n",
    "    \n",
    "    for batch_size in range(1, 65):\n",
    "        cleanup()\n",
    "        try:\n",
    "            input_data = torch.randn(batch_size, 3, 224, 224, device=device)\n",
    "            with torch.no_grad():\n",
    "                output = model(input_data)\n",
    "            \n",
    "            memory_used = get_memory_usage()\n",
    "            print(f\"배치 크기 {batch_size}: {memory_used:.1f}MB\")\n",
    "            max_batch = batch_size\n",
    "            \n",
    "            del input_data, output\n",
    "            \n",
    "            if memory_used > 2800:\n",
    "                break\n",
    "                \n",
    "        except RuntimeError:\n",
    "            print(f\"배치 크기 {batch_size}: 메모리 한계\")\n",
    "            break\n",
    "    \n",
    "    print(f\"최대 배치 크기 (224x224): {max_batch}\")\n",
    "    \n",
    "    # 3. 훈련 시 최대 배치 크기 (그래디언트 포함)\n",
    "    print(\"\\n3. 훈련 시 최대 배치 크기\")\n",
    "    cleanup()\n",
    "    \n",
    "    model.train()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    max_train_batch = 0\n",
    "    for batch_size in range(1, max_batch + 1):\n",
    "        cleanup()\n",
    "        try:\n",
    "            input_data = torch.randn(batch_size, 3, 224, 224, device=device)\n",
    "            target = torch.randint(0, 1000, (batch_size,), device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            memory_used = get_memory_usage()\n",
    "            print(f\"훈련 배치 {batch_size}: {memory_used:.1f}MB\")\n",
    "            max_train_batch = batch_size\n",
    "            \n",
    "            del input_data, target, output, loss\n",
    "            \n",
    "            if memory_used > 2700:  # 훈련은 더 보수적으로\n",
    "                break\n",
    "                \n",
    "        except RuntimeError:\n",
    "            print(f\"훈련 배치 {batch_size}: 메모리 한계\")\n",
    "            break\n",
    "    \n",
    "    print(f\"최대 훈련 배치 크기: {max_train_batch}\")\n",
    "    \n",
    "    # 4. 다양한 이미지 해상도별 최대 배치\n",
    "    print(\"\\n4. 해상도별 최대 배치 크기\")\n",
    "    cleanup()\n",
    "    \n",
    "    resolutions = [64, 128, 224, 320, 512]\n",
    "    model_simple = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(3, 64, 3, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 128, 3, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.AdaptiveAvgPool2d(1),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(128, 10)\n",
    "    ).to(device)\n",
    "    \n",
    "    for res in resolutions:\n",
    "        cleanup()\n",
    "        max_batch_res = 0\n",
    "        \n",
    "        for batch_size in range(1, 100):\n",
    "            try:\n",
    "                input_data = torch.randn(batch_size, 3, res, res, device=device)\n",
    "                with torch.no_grad():\n",
    "                    output = model_simple(input_data)\n",
    "                \n",
    "                memory_used = get_memory_usage()\n",
    "                max_batch_res = batch_size\n",
    "                \n",
    "                del input_data, output\n",
    "                \n",
    "                if memory_used > 2800:\n",
    "                    break\n",
    "                    \n",
    "            except RuntimeError:\n",
    "                break\n",
    "        \n",
    "        print(f\"해상도 {res}x{res}: 최대 배치 {max_batch_res}\")\n",
    "    \n",
    "    # 5. 행렬 곱셈 절대 한계\n",
    "    print(\"\\n5. 행렬 곱셈 절대 한계\")\n",
    "    cleanup()\n",
    "    \n",
    "    max_matmul_size = 0\n",
    "    for size in range(3000, 10000, 100):\n",
    "        cleanup()\n",
    "        try:\n",
    "            a = torch.randn(size, size, device=device)\n",
    "            b = torch.randn(size, size, device=device)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            c = torch.mm(a, b)\n",
    "            torch.cuda.synchronize()\n",
    "            compute_time = time.time() - start_time\n",
    "            \n",
    "            memory_used = get_memory_usage()\n",
    "            gflops = (2 * size**3) / (compute_time * 1e9)\n",
    "            \n",
    "            print(f\"크기 {size}: {compute_time:.3f}초, {gflops:.0f} GFLOPS, {memory_used:.1f}MB\")\n",
    "            max_matmul_size = size\n",
    "            \n",
    "            del a, b, c\n",
    "            \n",
    "            if memory_used > 2900:\n",
    "                break\n",
    "                \n",
    "        except RuntimeError:\n",
    "            print(f\"크기 {size}: 한계 도달\")\n",
    "            break\n",
    "    \n",
    "    print(f\"최대 행렬 곱셈 크기: {max_matmul_size}x{max_matmul_size}\")\n",
    "    \n",
    "    # 6. 메모리 처리량 한계 테스트\n",
    "    print(\"\\n6. 메모리 대역폭 한계\")\n",
    "    cleanup()\n",
    "    \n",
    "    sizes = [2048, 4096, 6144, 8192]\n",
    "    for size in sizes:\n",
    "        cleanup()\n",
    "        try:\n",
    "            # 메모리 복사 집약적 작업\n",
    "            data = torch.randn(size, size, device=device)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            for _ in range(100):\n",
    "                copied = data.clone()\n",
    "                del copied\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            copy_time = time.time() - start_time\n",
    "            data_size_gb = (size * size * 4 * 100) / 1024**3\n",
    "            bandwidth = data_size_gb / copy_time\n",
    "            \n",
    "            memory_used = get_memory_usage()\n",
    "            print(f\"크기 {size}: 대역폭 {bandwidth:.1f} GB/s, 메모리 {memory_used:.1f}MB\")\n",
    "            \n",
    "            del data\n",
    "            \n",
    "        except RuntimeError:\n",
    "            print(f\"크기 {size}: 메모리 부족\")\n",
    "            break\n",
    "    \n",
    "    # 7. 최종 한계 요약\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"GTX 1060 3GB 절대 한계 요약\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"최대 단일 텐서 크기: {max_size}x{max_size}\")\n",
    "    print(f\"최대 추론 배치 (224x224): {max_batch}\")\n",
    "    print(f\"최대 훈련 배치 (224x224): {max_train_batch}\")\n",
    "    print(f\"최대 행렬 곱셈: {max_matmul_size}x{max_matmul_size}\")\n",
    "    print(\"\\n권장 안전 사용량:\")\n",
    "    print(f\"- 추론 배치: {max_batch//2} 이하\")\n",
    "    print(f\"- 훈련 배치: {max_train_batch//2} 이하\")\n",
    "    print(f\"- 행렬 크기: {max_matmul_size//2} 이하\")\n",
    "    print(\"- 메모리 사용률: 80% 이하 유지\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    limit_performance_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cfc0d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1060 3GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True가 출력되면 GPU 사용 가능\n",
    "print(torch.cuda.get_device_name(0))  # GPU 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe15f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
